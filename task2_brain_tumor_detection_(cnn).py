# -*- coding: utf-8 -*-
"""task2_Brain_Tumor_Detection_(CNN).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cAZqoMaJo6DErvAWuzmIJ2Ssilgq8r-E
"""

!pip install opendatasets

import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix,classification_report
import opendatasets as od
import pandas as pd
from tensorflow.keras.callbacks import EarlyStopping
import seaborn as sns
from tensorflow.keras.optimizers import AdamW

od.download("https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset")

train_ds_raw = tf.keras.utils.image_dataset_from_directory(
    "/content/brain-tumor-mri-dataset/Training",
    image_size=(128,128),
    batch_size=32,
    label_mode="categorical" , shuffle = True
)

test_ds_raw = tf.keras.utils.image_dataset_from_directory(
    "/content/brain-tumor-mri-dataset/Testing",
    image_size=(128,128),
    batch_size=32,
    label_mode="categorical",shuffle = False
)

class_names = train_ds_raw.class_names

plt.figure(figsize=(10,10))
for images,labels in train_ds_raw.take(1):
  for i in range(9):
    ax = plt.subplot(3,3,i+1)
    plt.imshow(images[i].numpy().astype("uint8"))
    label_index = labels[i].numpy().argmax()
    plt.title(class_names[label_index])
    plt.axis("off")


normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds = train_ds_raw.map(lambda x,y: (normalization_layer(x),y))
test_ds  = test_ds_raw.map(lambda x,y: (normalization_layer(x),y))

model = models.Sequential([
    layers.Conv2D(32,(3,3),activation="relu",input_shape=(128,128,3),padding='same'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64,(3,3),activation="relu",padding='same'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(128,(3,3),activation="relu",padding='same'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(128,activation="relu"),
    layers.Dropout(0.5),
    layers.Dense(4,activation="softmax")

])
model.compile(optimizer=AdamW(learning_rate=0.001),loss="categorical_crossentropy",metrics=["accuracy"])

early_s = EarlyStopping(monitor='val_loss', patience=15, verbose=1,restore_best_weights=True)
history = model.fit(train_ds,epochs=500,validation_data=test_ds,callbacks=[early_s])

loss,acc = model.evaluate(test_ds)
print("Loss: ",loss)
print("Accuracy: ",acc)

y_true = np.concatenate([y for x, y in test_ds], axis=0)
y_true = np.argmax(y_true, axis=1)

y_pred = model.predict(test_ds)
y_pred = np.argmax(y_pred, axis=1)


cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt='d',
            xticklabels=class_names,
            yticklabels=class_names,
            cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title("Confusion Matrix")
plt.show()


print(classification_report(y_true, y_pred, target_names=class_names))

model.save("brain_tumor_multiclass_cnn.h5")
from google.colab import files
files.download("brain_tumor_multiclass_cnn.h5")

requirements = """streamlit
tensorflow
numpy
pillow
seaborn
scikit-learn
matplotlib
pandas
"""

with open("requirements.txt", "w") as f:
    f.write(requirements)
from google.colab import files
files.download("requirements.txt")